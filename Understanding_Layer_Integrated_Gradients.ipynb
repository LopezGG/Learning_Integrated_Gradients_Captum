{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I am going to show \n",
    "1. Results from library method of Layer Integrated Gradients\n",
    "2. A barebones implementation of the logic for layer Integrated Gradients\n",
    "3. show a simplified implementation of library code <br>\n",
    "I will start with a simple Neural Net and work my way. The final cell shows the results from all the 3 methods. We will be using hooks. To get an understanding on hooks , I will leave some study materials link towards the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from captum.attr import LayerIntegratedGradients,IntegratedGradients\n",
    "from IPython.display import Image\n",
    "from torch.nn import Module\n",
    "from typing import Any, Callable, Dict, List, Tuple, Union, cast, overload\n",
    "from torch import Tensor, device\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Layer Integrated gradients we will try and find out how much each neuron of linear_layer contributes to the final output. For sake of simplicity, we are assuming a single cpu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleNN,self).__init__()\n",
    "        self.input_linear = nn.Linear(in_features=input_dim,out_features=3,bias=True) # takes 2 features and outputs 3 \n",
    "        self.hidden= nn.Linear(in_features=3,out_features=2,bias=True) #one output for each class\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_linear(x))\n",
    "        x= torch.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inData = torch.rand((1,input_dim),requires_grad=True) # shape is [1,3] Imagine this to be a word with 3 dimensional vector [batch_size,num_dim]\n",
    "baseline = torch.rand((1,input_dim),requires_grad=True)\n",
    "target_index = 1 # index of second class\n",
    "num_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_i(inputs):\n",
    "    logits = net(inputs) # I cant pass the model itself as a parameter to IntegratedGradients\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleNN(\n",
       "  (input_linear): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (hidden): Linear(in_features=3, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = simpleNN()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captum Library Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(predict_i,net.input_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions_dim_linear_layer = lig.attribute(inputs=(inData),\n",
    "                                  baselines=(baseline),\n",
    "                                   n_steps=num_steps,\n",
    "                                   target =target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution of each nueron in the linear layer\n",
      "tensor([[-0.0020, -0.0035, -0.0004]], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Attribution of each nueron in the linear layer\")\n",
    "print (attributions_dim_linear_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BareBones LayerIntegratedGradients Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. take the input and run it through a forward network and get the value of the neuron for that input. \n",
    "2. Mimic integrated gradient but instead of running through the entire network, short circuit it with a hook so that we run the network only upto linear layer. This means instead of generating values for the neuron at the linear layer, we will provide values for this neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the ouput of the linear layer \n",
    "def run_forward_get_layer_output(forward_fn,inputs,layer_which_needs_hook):\n",
    "    saved_layer = {}\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    def forward_hook(module, inp, out=None): # hook is created on a module and is automatically fed input and output of that module\n",
    "        eval_tsrs = (out,)\n",
    "        with lock: # this is used for help with distributed computing. When we are using one device like now, this becomes non-essential\n",
    "            nonlocal saved_layer # TODO: Check if nonlocals must be bound by a function\n",
    "            saved_layer[eval_tsrs[0].device] = tuple(\n",
    "                        eval_tsr.clone() for eval_tsr in eval_tsrs\n",
    "                    ) # we are saving the output of the module to a global \n",
    "    hook = None\n",
    "    try:\n",
    "        hook = layer_which_needs_hook.register_forward_hook(forward_hook)\n",
    "        output = forward_fn(inputs[0])\n",
    "    finally:\n",
    "        if hook is not None:\n",
    "            hook.remove()\n",
    "    if len(saved_layer) == 0:\n",
    "        raise AssertionError(\"Forward hook did not obtain any outputs for given layer\")\n",
    "    return saved_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{device(type='cpu'): (tensor([[ 0.2989,  0.1808, -0.1334]], grad_fn=<CloneBackward>),)}\n"
     ]
    }
   ],
   "source": [
    "inputs = (inData,) # converting this to a tuple\n",
    "inputs_layer = run_forward_get_layer_output(\n",
    "                        predict_i,\n",
    "                        inputs,\n",
    "                        net.input_linear)\n",
    "print(inputs_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the first hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values can simply be derived as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2989, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_index = 0\n",
    "(net.input_linear.weight[neuron_index][0] *inputs[0][0][0] ) + (net.input_linear.weight[neuron_index][1] *inputs[0][0][1] ) \\\n",
    "+ net.input_linear.bias[neuron_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OR can be simply derived as*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2989, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_index = 0\n",
    "torch.matmul(inputs[0][0],net.input_linear.weight[neuron_index]) + net.input_linear.bias[neuron_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1808, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_index = 1\n",
    "torch.matmul(inputs[0][0],net.input_linear.weight[neuron_index]) + net.input_linear.bias[neuron_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1334, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_index = 2\n",
    "torch.matmul(inputs[0][0],net.input_linear.weight[neuron_index]) + net.input_linear.bias[neuron_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining output of linear layer  for baseline using first hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{device(type='cpu'): (tensor([[-0.0988,  0.0514,  0.1107]], grad_fn=<CloneBackward>),)}\n"
     ]
    }
   ],
   "source": [
    "base_inputs = (baseline,) # converting this to a tuple\n",
    "baselines_layer = run_forward_get_layer_output(\n",
    "                        predict_i,\n",
    "                        base_inputs,\n",
    "                        net.input_linear)\n",
    "print(baselines_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping to run Intergrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = torch.linspace(0, 1, num_steps).unsqueeze(-1) #[10, 1] i.e 10 columns , equally spaced points between 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2989,  0.1808, -0.1334]], grad_fn=<CloneBackward>)\n",
      "tensor([[-0.0988,  0.0514,  0.1107]], grad_fn=<CloneBackward>)\n"
     ]
    }
   ],
   "source": [
    "linear_output = list(inputs_layer.values())[0][0]\n",
    "print(linear_output)\n",
    "linear_output_base = list(baselines_layer.values())[0][0]\n",
    "print(linear_output_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the data points shown below , first row is the linear out of baseline and last row is the linear out of input Data\n",
      "[[-0.09882952  0.05136591  0.11071467]\n",
      " [-0.0546359   0.06574471  0.08358987]\n",
      " [-0.01044229  0.08012351  0.05646508]\n",
      " [ 0.03375132  0.09450231  0.02934029]\n",
      " [ 0.07794493  0.10888111  0.0022155 ]\n",
      " [ 0.12213854  0.12325991 -0.0249093 ]\n",
      " [ 0.16633216  0.13763872 -0.05203409]\n",
      " [ 0.21052575  0.1520175  -0.07915888]\n",
      " [ 0.25471938  0.1663963  -0.10628367]\n",
      " [ 0.29891297  0.1807751  -0.13340846]]\n"
     ]
    }
   ],
   "source": [
    "delta_points_np = (linear_output_base + dim1 * (linear_output - linear_output_base)).detach().numpy() #(10, num_neuron). Here dim1 is broadcast\n",
    "print(\"In the data points shown below , first row is the linear out of baseline and last row is the linear out of input Data\")\n",
    "print(delta_points_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Hook for computing gradients for these 10 points "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model actually takes in the forward. By adding a hook, we shortcuit the forward function of the model. Instead of computing the output of the linear layer, the hook returns the value we ask it return. This value is the one we computed as delta_points_np based on input & baseline's linear layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_l = []\n",
    "with torch.autograd.set_grad_enabled(True):\n",
    "    # instead of starting from input, this hook here just returns the output of the first linear layer\n",
    "    def layer_forward_hook(module, hook_inputs, hook_outputs=None):\n",
    "        device = hook_outputs[0].device #cpu\n",
    "        return scattered_inputs_dict[device]\n",
    "    hook = net.input_linear.register_forward_hook(layer_forward_hook)\n",
    "    for row in delta_points_np:\n",
    "        delta_input = torch.tensor([row],requires_grad=True) \n",
    "        scattered_inputs = (delta_input,)\n",
    "        scattered_inputs_dict = {\n",
    "                        scattered_input[0].device: scattered_input\n",
    "                        for scattered_input in scattered_inputs\n",
    "                    }\n",
    "        output = net(inData)\n",
    "        target_Dp = output[0][target_index].unsqueeze(-1) # this extracts the probability of the class we are interested in \n",
    "        grads = torch.autograd.grad(target_Dp.unsqueeze(-1), delta_input)\n",
    "        gradient_l.append(grads[0])\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000, -0.0266,  0.0033]]),\n",
       " tensor([[ 0.0000, -0.0266,  0.0033]]),\n",
       " tensor([[ 0.0000, -0.0267,  0.0033]]),\n",
       " tensor([[-0.0065, -0.0267,  0.0033]]),\n",
       " tensor([[-0.0065, -0.0267,  0.0033]]),\n",
       " tensor([[-0.0065, -0.0268,  0.0000]]),\n",
       " tensor([[-0.0065, -0.0268,  0.0000]]),\n",
       " tensor([[-0.0065, -0.0268,  0.0000]]),\n",
       " tensor([[-0.0065, -0.0268,  0.0000]]),\n",
       " tensor([[-0.0066, -0.0268,  0.0000]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a function that takes in a list of gradient tensors and returns the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0066, -0.0268,  0.0000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTensorMean(TensorList):\n",
    "    tensor_2D = torch.stack(TensorList)\n",
    "    return torch.mean(tensor_2D,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means of gradients of 10 vectors between input and baseline\n",
      "tensor([[-0.0046, -0.0267,  0.0017]])\n"
     ]
    }
   ],
   "source": [
    "gradient_l_mean = getTensorMean(gradient_l)\n",
    "print(\"The means of gradients of 10 vectors between input and baseline\")\n",
    "print(gradient_l_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we take the difference between linear layer of input  and baseline. This is a straight line between input and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3977,  0.1294, -0.2441]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = (linear_output-linear_output_base)\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying it by the difference of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions from simplified version of the code\n",
      "\t -0.00182\n",
      "\t -0.00346\n",
      "\t -0.0004\n"
     ]
    }
   ],
   "source": [
    "attributions = gradient_l_mean * diff\n",
    "print(\"Attributions from simplified version of the code\")\n",
    "for att in attributions[0]:\n",
    "    print(\"\\t\", round(att.item(),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified  Library Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be re-using the following from previous sections \n",
    "1. linear_output of input and base \n",
    "2. layer_forward_hook\n",
    "Some of the key differences are\n",
    "1. Instead of taking equally spaced points , we generate these points with gausian legrande function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Datapoints and target vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sizes = list(0.5 * np.polynomial.legendre.leggauss(num_steps)[1])\n",
    "alphas = list(0.5 * (1 + np.polynomial.legendre.leggauss(num_steps)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.cat(num_steps* [torch.tensor([target_index])]) #[num_steps] [10]\n",
    "target = target.reshape(num_steps, 1) #[num_steps,1] [10, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running through Ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_points =torch.cat([linear_output_base + alpha * (linear_output - linear_output_base) for alpha in alphas],dim=0).requires_grad_() #[10,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scattered_inputs is the value of the linear layer for each delta_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{device(type='cpu'): tensor([[-0.0936,  0.0531,  0.1075],\n",
       "         [-0.0720,  0.0601,  0.0942],\n",
       "         [-0.0351,  0.0721,  0.0716],\n",
       "         [ 0.0139,  0.0880,  0.0416],\n",
       "         [ 0.0704,  0.1064,  0.0068],\n",
       "         [ 0.1296,  0.1257, -0.0295],\n",
       "         [ 0.1862,  0.1441, -0.0642],\n",
       "         [ 0.2352,  0.1600, -0.0943],\n",
       "         [ 0.2721,  0.1720, -0.1169],\n",
       "         [ 0.2937,  0.1791, -0.1302]], grad_fn=<CatBackward>)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scattered_inputs = (delta_points,)\n",
    "scattered_inputs\n",
    "scattered_inputs_dict = {\n",
    "                scattered_input[0].device: scattered_input\n",
    "                for scattered_input in scattered_inputs\n",
    "            }\n",
    "scattered_inputs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier the model takes actual input with n_dim , we will later shortcircuit it with scattered_inputs by using the hook. So we need to replicate our input n_steps times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inData_rep = torch.cat(10* [inData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_grad_enabled(True):\n",
    "        # instead of starting from input, this hook here just returns the output of the first linear layer\n",
    "        def layer_forward_hook(module, hook_inputs, hook_outputs=None):\n",
    "            device = None\n",
    "            if hook_outputs is not None and len(hook_outputs) > 0:\n",
    "                device = hook_outputs[0].device #cpu\n",
    "            else:\n",
    "                params = list(module.parameters())\n",
    "                device = params[0].device #cpu\n",
    "            return scattered_inputs_dict[device]\n",
    "        hook = net.input_linear.register_forward_hook(layer_forward_hook)\n",
    "        output = net(inData_rep)\n",
    "        hook.remove()\n",
    "        target_Dp = torch.gather(output, 1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = torch.autograd.grad(torch.unbind(target_Dp), delta_points) # torch.unbind removes one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000, -0.0009,  0.0001],\n",
       "         [ 0.0000, -0.0020,  0.0002],\n",
       "         [ 0.0000, -0.0029,  0.0004],\n",
       "         [-0.0009, -0.0036,  0.0004],\n",
       "         [-0.0010, -0.0039,  0.0005],\n",
       "         [-0.0010, -0.0040,  0.0000],\n",
       "         [-0.0009, -0.0036,  0.0000],\n",
       "         [-0.0007, -0.0029,  0.0000],\n",
       "         [-0.0005, -0.0020,  0.0000],\n",
       "         [-0.0002, -0.0009,  0.0000]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening grads so that we can multilpy it with step-size\n",
    "# calling contiguous to avoid `memory whole` problems\n",
    "n_steps=10\n",
    "scaled_grads = [\n",
    "    grad.contiguous().view(n_steps, -1)\n",
    "    * torch.tensor(step_sizes).view(n_steps, 1).to(grad.device)\n",
    "    for grad in grads\n",
    "]\n",
    "scaled_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "def _reshape_and_sum(\n",
    "    tensor_input: Tensor, num_steps: int, num_examples: int, layer_size: Tuple[int, ...]\n",
    ") -> Tensor:\n",
    "    # Used for attribution methods which perform integration\n",
    "    # Sums across integration steps by reshaping tensor to\n",
    "    # (num_steps, num_examples, (layer_size)) and summing over\n",
    "    # dimension 0. Returns a tensor of size (num_examples, (layer_size))\n",
    "    return torch.sum(\n",
    "        tensor_input.reshape((num_steps, num_examples) + layer_size), dim=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradients after smoothing it out a bit\n",
      "\t -0.005100629017714776\n",
      "\t -0.02673791069551692\n",
      "\t 0.0016568139610821965\n"
     ]
    }
   ],
   "source": [
    "# aggregates across all steps for each tensor in the input tuple\n",
    "# total_grads has the same dimensionality as inputs\n",
    "total_grads = [\n",
    "    _reshape_and_sum(\n",
    "        tensor_input=scaled_grad, num_steps=n_steps, num_examples=grad.shape[0] // n_steps, layer_size=grad.shape[1:] # // is integer division\n",
    "    )\n",
    "    for (scaled_grad, grad) in zip(scaled_grads, grads)\n",
    "]\n",
    "print (\"Total gradients after smoothing it out a bit\")\n",
    "for tg in total_grads[0][0]:\n",
    "    print(\"\\t\",tg.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing it with the mean we generated with barebones method in cell 24\n",
      "\t -0.0045677898451685905\n",
      "\t -0.026735519990324974\n",
      "\t 0.0016566950362175703\n"
     ]
    }
   ],
   "source": [
    "print (\"Comparing it with the mean we generated with barebones method in cell 24\")\n",
    "for tg in gradient_l_mean[0]:\n",
    "    print(\"\\t\",tg.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes attribution for each tensor in input tuple\n",
    "# attributions has the same dimensionality as inputs\n",
    "attributions_expanded_code = tuple(\n",
    "    total_grad * (inputRow - base)\n",
    "    for total_grad, inputRow, base in zip(total_grads, linear_output , linear_output_base)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions from library code\n",
      "\t -0.00203\n",
      "\t -0.00346\n",
      "\t -0.0004\n",
      "Attributions from simplified version of the code\n",
      "\t -0.00182\n",
      "\t -0.00346\n",
      "\t -0.0004\n",
      "attributions from simplified library code\n",
      "\t -0.00203\n",
      "\t -0.00346\n",
      "\t -0.0004\n"
     ]
    }
   ],
   "source": [
    "print(\"Attributions from library code\")\n",
    "for att in attributions_dim_linear_layer[0]:\n",
    "    print(\"\\t\", round(att.item(),5))\n",
    "\n",
    "print(\"Attributions from simplified version of the code\")\n",
    "for att in attributions[0]:\n",
    "    print(\"\\t\", round(att.item(),5))\n",
    "    \n",
    "print(\"attributions from simplified library code\")\n",
    "for att in attributions_expanded_code[0][0]:\n",
    "    print(\"\\t\", round(att.item(),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Materials\n",
    "1. https://github.com/Paperspace/PyTorch-101-Tutorial-Series\n",
    "2. https://blog.paperspace.com/pytorch-101-advanced/ \n",
    "3. https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/\n",
    "4. https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/\n",
    "5. https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret_k1",
   "language": "python",
   "name": "interpret_k1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
